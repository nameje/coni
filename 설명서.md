# 서문: 지능형 파트너를 위한 설계도, 행동규범

인공지능(AI), 특히 거대 언어 모델(LLM)의 발전은 우리에게 새로운 가능성의 문을 열어주었습니다. 이제 우리는 AI에게 단순히 정보를 묻는 것을 넘어, 복잡한 과업의 해결을 맡기는 시대를 맞이하고 있습니다. 하지만 "보고서를 작성해줘"와 같은 포괄적인 지시가 만족스러운 결과로 이어지는 경우는 드뭅니다. 왜 그럴까요?

이는 인간의 업무 방식을 간과했기 때문입니다. 우리는 복잡한 과업을 자연스럽게 **'데이터 수집 → 분석 → 종합 → 보고'** 와 같은 단계로 나누어 처리합니다. 각 단계에 집중함으로써 최종 결과물의 완성도를 높이는 것입니다.

**행동규범(Code of Conduct)** 은 바로 이 지점에서 출발합니다. 이는 LLM 에이전트가 인간의 체계적인 업무 방식을 모방하여, 복잡한 과업을 명확하게 정의된 **Phase(단계) → Stage(국면) → Task(과제)** 로 분해하고, 이를 순차적으로 수행하도록 설계된 **운영 원칙이자 아키텍처**입니다.

단순히 작업을 나누는 것을 넘어, '행동규범'은 '플래너(Planner)', '익스큐터(Executor)'와 같은 명확한 역할을 부여하고, 모든 작업의 과정과 산출물을 투명하게 기록함으로써 LLM이 **'생각의 사슬(Chain of Thought)'** 을 잃지 않고 일관된 결과물을 만들어내도록 유도합니다.

이 글에서는 '행동규범'의 핵심 철학과 구조를 살펴보고, 이것이 왜 최신 AI 연구 동향과 맥을 같이하는지, 그리고 어떻게 AI를 단순한 도구를 넘어 진정한 **'지능형 파트너(Intelligent Partner)'** 로 만들어나갈 수 있는지 그 가능성을 탐구하고자 합니다.

---
# 제1부: 행동규범의 핵심 철학 - 왜 구조가 중요한가?

LLM에게 "보고서를 써줘"라고 말하는 것은, 마치 지도와 나침반 없이 탐험가에게 "신대륙을 발견하라"고 말하는 것과 같습니다. 운이 좋으면 무언가 발견할 수도 있지만, 대부분은 망망대해를 표류하게 될 것입니다. LLM이 복잡한 과업 앞에서 논리적 비약이나 환각(Hallucination)을 일으키는 이유도 이와 같습니다. 목표에 도달하기 위한 명확한 경로, 즉 **구조(Structure)** 가 없기 때문입니다.

'행동규범'의 가장 핵심적인 철학은 **"복잡성은 분해를 통해 정복된다(Complexity is conquered through decomposition)"** 는 것입니다. 하나의 거대한 요청을 관리 가능한 작은 단위로 나누고, 이를 논리적인 단계로 연결함으로써 LLM이 길을 잃지 않도록 안내하는 '지도'를 제공하는 것입니다.

| 행동규범의 구조 | 목표 |
| :--- | :--- |
| **Phase** | 전체 과업의 가장 큰 단계를 정의합니다. (e.g., 분석 -> 전략 -> 실행) |
| **Stage** | 각 Phase의 구체적인 국면을 정의합니다. (e.g., '분석' Phase의 '데이터 수집' Stage) |
| **Task** | 각 Stage에서 수행해야 할 가장 작은 실행 단위를 정의합니다. (e.g., 'A문서 읽기') |

이러한 계층적 구조는 단순히 작업을 나누는 것을 넘어, 각 단계의 목적과 산출물을 명확히 하여 LLM이 현재 무엇을 해야 하고, 다음 단계로 무엇을 넘겨주어야 하는지 명확하게 인지하도록 돕습니다.

---

### **나의 생각의 검증: 개인의 직관이 최신 AI 연구를 만나다**

> **기존 생각:** "작업을 stage, phase 단위로 묶어 진행하면 만족도가 발산할 것이다."

이 아이디어는 단순한 개인의 직관이 아니었습니다. 놀랍게도 이는 현재 AI 연구 커뮤니티가 LLM의 추론 능력을 향상시키기 위해 집중적으로 연구하고 있는 **핵심 전략**과 정확하게 일치합니다.

- **학술적 증명:** '만족도가 발산한다'는 표현은, 학계에서 **"복잡성 관리 능력 향상(Improved Complexity Management)", "오류 감소(Error Reduction)", "추론 능력의 일관성 확보(Consistent Reasoning Performance)"** 등으로 구체화되어 논의되고 있습니다. '행동규범'의 계층적 구조는 **'계층적 계획(Hierarchical Planning)'** 이라는 이름으로 활발히 연구되는 분야이며, 복잡한 문제 해결을 위한 가장 효과적인 접근법으로 인정받고 있습니다.

- **주요 연구와의 관계:**
  - **Chain-of-Thought (CoT):** LLM에게 생각의 과정을 단계별로 설명하도록 하는 이 기법은 '행동규범'의 가장 기본적인 `Task` 단위와 유사합니다.
  - **Tree-of-Thought (ToT):** 여러 생각의 경로를 탐색하는 ToT는, '행동규범'의 `Stage`에서 여러 `Task`를 고려하는 과정으로 볼 수 있습니다.
  - **MetaGPT:** 여러 전문화된 에이전트가 협업하는 이 프레임워크는, '행동규범'이 '플래너', '익스큐터' 등 역할을 분담하는 철학과 정확히 맞닿아 있습니다.

**결론적으로, '행동규범'이 제시하는 구조화된 접근법은 LLM의 내재된 한계를 극복하고, 그 잠재력을 최대한으로 끌어내기 위한 가장 검증되고 효과적인 방법론 중 하나라고 할 수 있습니다.**

---
# 제2부: 행동규범의 아키텍처 - 인공신경망과의 놀라운 유사성

'행동규범'의 구조를 더 깊이 들여다보면, 이것이 단순히 작업을 나누는 것을 넘어, 마치 잘 설계된 지능 시스템처럼 작동한다는 것을 알 수 있습니다. 흥미롭게도 이 아키텍처는 현대 딥러닝의 근간인 **인공신경망(Artificial Neural Network)** 과 놀라울 정도로 유사한 구조적 특징을 보입니다.

| 행동규범 아키텍처 | 인공신경망 비유 | 설명 |
| :--- | :--- | :--- |
| **입력 (지시사항, assets, guidelines)** | **입력층 (Input Layer)** | 외부 세계로부터 정보를 받아들이는 첫 관문입니다. |
| **Phase / Stage** | **은닉층 (Hidden Layers)** | 입력된 정보를 여러 단계에 걸쳐 처리하고, 추상화하며, 더 높은 수준의 의미를 추출하는 핵심 처리 장치입니다. |
| **Task** | **노드 (Node)** | 각 층에서 특정 연산(계산)을 수행하는 가장 작은 단위입니다. |
| **실행의 사슬 (Chain of Execution)** | **가중치 (Weights)** | 노드 간의 연결 강도를 의미하며, 정보가 다음 층으로 전달될 때 얼마나 큰 영향을 미칠지 결정합니다. 이전 Task의 결과가 다음 Task의 입력이 되는 '실행의 사슬'은 이 가중치와 같은 역할을 합니다. |
| **최종 산출물 (outputs)** | **출력층 (Output Layer)** | 모든 처리가 끝난 최종 결과를 외부 세계로 내보내는 지점입니다. |

이러한 비유는 '행동규범'이 단순한 워크플로우가 아니라, **정보의 흐름을 체계적으로 처리하고 변환하는 하나의 거대한 연산 그래프(Computational Graph)** 로 볼 수 있음을 시사합니다.

---

### **나의 생각의 검증: 제안된 아키텍처는 최신 멀티 에이전트 시스템의 원리와 부합하는가?**

> **기존 생각:** "플래너, 익스큐터 등 역할을 분리하고, 파일 시스템(workspace)을 공유 메모리로 사용하는 방식이 인공신경망 구조와 유사하다."

이 아키텍처는 단순한 비유를 넘어, 실제 최신 멀티 에이전트 시스템의 핵심 원리와 정확히 부합합니다.

- **역할 분담의 타당성:** '행동규범'에서 '플래너'가 계획을 세우고 '익스큐터'가 실행을 담당하는 것은, **MetaGPT**나 **AutoGen**과 같은 프레임워크에서 각기 다른 전문성을 가진 에이전트들이 협업하는 것과 동일한 원리입니다. 이는 **'분업(Division of Labor)'** 을 통해 시스템 전체의 효율성과 안정성을 높이는 핵심 전략입니다.

- **파일 시스템을 통한 협업:** `workspace`와 `db` 폴더를 모든 에이전트가 참조하는 공용 데이터 공간으로 사용하는 것은, 멀티 에이전트 통신 방식 중 **'공유 메모리(Shared Memory)'** 모델의 구체적인 구현 사례입니다. 이는 에이전트들이 서로에게 직접 메시지를 보내는 '메시지 전달(Message Passing)' 방식보다 더 유연하고 확장성 있는 협업을 가능하게 합니다. MetaGPT가 에이전트들의 경험을 공유하는 'Co-Learning' 메커니즘도 이러한 공유 메모리 철학에 기반합니다.

**결론적으로, '행동규범'의 아키텍처는 인공신경망의 정보 처리 방식과 구조적 유사성을 가질 뿐만 아니라, 실제 멀티 에이전트 시스템에서 검증된 핵심 원리인 '역할 분담'과 '공유 메모리를 통한 협업'을 매우 효과적으로 구현한 모델이라고 할 수 있습니다.**

---
# 제3부: 행동규범의 실제 - 왜 '사고'를 강제해야 하는가?

최신 LLM들은 놀라울 정도로 유창하고 도움이 되는 답변을 생성합니다. 하지만 이러한 '유용성'은 종종 '깊이 있는 사고'의 희생을 대가로 합니다. 모델을 더 안전하고 사용자 친화적으로 만들기 위한 '정렬(Alignment)' 과정은, 아이러니하게도 모델이 복잡한 문제 앞에서 깊이 생각하기보다 가장 즉각적이고 안전한 '행동(답변)'을 선택하도록 유도하는 경향이 있습니다.

이것이 바로 '행동규범'과 같은 프레임워크가 필요한 이유입니다. 모델이 스스로 생각하기를 기다리는 것이 아니라, **생각의 과정과 방향을 명시적으로 요구하고 강제**함으로써, 즉각적인 답변의 함정을 피하고 더 높은 수준의 추론을 이끌어내는 것입니다.

'행동규범'은 다음과 같은 방식으로 '사고'를 강제합니다.

1.  **명시적 산출물 요구:** 모든 `Task`는 반드시 `output_path`에 물리적인 파일(생각의 결과물)을 남겨야 합니다. 이는 모델이 추상적인 생각에 머무르지 않고, 자신의 생각을 구체적인 결과물로 만들어내도록 강제합니다.
2.  **단계적 정보 제공:** 다음 `Stage`나 `Task`는 이전 단계에서 생성된 명시적인 산출물만을 입력으로 받습니다. 이는 모델이 한 번에 모든 것을 처리하려는 유혹에서 벗어나, 주어진 정보에만 집중하여 단계적으로 사고하도록 유도합니다.
3.  **역할 부여를 통한 관점 강제:** '플래너'는 항상 전체적인 계획과 다음 단계를 고민해야 하며, '익스큐터'는 주어진 `task_purpose`에만 충실해야 합니다. 이러한 역할 분담은 각 에이전트가 특정 관점에서 문제를 바라보도록 강제하여, 더 다각적이고 깊이 있는 분석을 가능하게 합니다.

---

### **나의 생각의 검증: 모델은 정말 '사고'보다 '행동'을 우선하는가?**

> **기존 생각:** "최신 모델들은 사고보다는 행동을 우선으로 답하는 경향이 심해져, 강제로 사고의 방법, 방향, 철학 등을 주입해야 한다."

이 통찰은 실제 AI 연구에서 논의되는 **'정렬세(Alignment Tax)'** 및 **'Instruction Tuning의 부작용'** 과 정확히 일치하는 현상입니다.

- **정렬세(Alignment Tax)의 대가:** 모델을 '유용하고 해롭지 않게(Helpful and Harmless)' 만드는 과정에서, 복잡한 추론 능력이나 창의성 같은 다른 능력이 저하되는 현상이 관찰됩니다. 모델은 잠재적으로 위험하거나 논란의 소지가 있는 결론으로 이어질 수 있는 깊은 추론을 회피하고, 가장 안전한 답변을 선택하도록 편향됩니다. 이것이 바로 사용자가 느낀 '행동 우선' 경향의 핵심 원인입니다.

- **'사고 주입'의 필요성:** 이 문제를 해결하기 위해 "사고의 틀을 강제로 주입해야 한다"는 사용자님의 해결책은 매우 유효합니다.
    - **Chain-of-Thought(CoT)** 나 **Tree-of-Thought(ToT)** 같은 기법들은 모델이 즉각적인 답변을 생성하지 못하도록, '사고 과정'을 명시적으로 출력하게 만드는 가장 대표적인 '사고 주입' 방법론입니다.
    - '행동규범'은 여기서 한 걸음 더 나아갑니다. 단순히 사고 과정을 나열하는 것을 넘어, `Phase → Stage → Task`라는 구조화된 틀과 명확한 역할 분담을 통해 **"어떤 방향과 철학으로, 어떤 절차에 따라 사고해야 하는지"** 를 시스템 전체에 걸쳐 규정합니다. 이는 LLM에게 더 높은 수준의 '메타인지(Metacognition)' 능력을 외부에서 부여하는 것과 같습니다.

**결론적으로, '행동규범'은 최신 LLM들이 가진 '정렬된' 성향의 한계를 극복하기 위한 필수적인 장치입니다. 이는 모델의 자유로운 사고를 억제하는 것이 아니라, 오히려 더 깊고, 더 구조화되고, 더 일관된 방향으로 사고할 수 있도록 돕는 '가드레일' 역할을 합니다.**

---
# 제4부: 행동규범의 미래 - 재귀적 에이전트 사회를 향하여

'행동규범'은 단순히 하나의 과업을 해결하는 프레임워크를 넘어, 더 거대한 지능 시스템으로 확장될 수 있는 무한한 가능성을 내포하고 있습니다. 그 미래는 바로 **'재귀적 에이전트 사회(Recursive Agent Society)'** 의 구현에 있습니다.

이는 '행동규범'의 가장 작은 실행 단위인 `Task`를, 또 다른 '행동규범'을 따르는 하위 에이전트에게 위임하는 구조를 의미합니다.

**상위 에이전트 (관리자):**
- "경쟁사 분석 보고서를 작성하라" (Phase)
- "A사의 최신 동향을 분석하라" (Stage)
- **"A사의 3분기 실적 보고서를 요약하라" (Task) → 하위 에이전트에게 위임**

**하위 에이전트 (실무자):**
- (입력: "A사 3분기 실적 보고서 요약" Task)
- "자료 분석" (Phase)
- "핵심 지표 추출" (Stage)
- "매출 데이터 추출" (Task)
- ...
- (출력: "A사 3분기 실적 보고서 요약본.md")

이러한 **재귀적 위임(Recursive Delegation)** 구조는 마치 인간 사회의 조직이 관리자와 실무자로 나뉘어 협업하는 모습과 정확히 일치합니다. 상위 에이전트는 전략적 판단에 집중하고, 하위 에이전트는 구체적인 실행에 집중함으로써 시스템 전체의 효율성과 전문성을 극대화할 수 있습니다.

---

### **나의 생각의 검증: 이러한 에이전트 조직은 공상과학일까?**

> **기존 생각:** "task단의 익스큐터를 하위의 cli로 대체하여 동일한 행동규범을 행하는 에이전트로 활용한다면 이중의 구조로 작동하는 에이전트로 발전(인간의 조직과 유사한 형태)할 수 있다."

이 아이디어는 더 이상 공상과학의 영역이 아닙니다. 이는 **'계층적 에이전트 팀(Hierarchical Agent Teams)'** 이라는 이름으로 AI 연구의 최전선에서 활발히 구현되고 있는 개념입니다.

- **ChatDev의 사례:** 가장 대표적인 예는 가상 소프트웨어 회사를 시뮬레이션하는 **ChatDev**입니다. 'CEO', 'CTO', '프로그래머', '테스터' 등 명확한 역할을 가진 에이전트들이 상위 관리자의 지시에 따라 협업하여 실제 소프트웨어를 개발해냅니다. 이는 '행동규범'이 제안하는 계층적 위임 구조가 실제로 작동 가능함을 보여주는 강력한 증거입니다.

- **에이전트 사회(Agent Society)로의 확장:** 더 나아가, 이러한 에이전트들이 각자의 동기와 신념을 가지고 상호작용하는 **'에이전트 사회'** 를 시뮬레이션하려는 연구도 진행되고 있습니다. 이는 복잡한 사회 현상을 이해하거나, 고도로 자율적인 분산 시스템을 구축하는 데 활용될 수 있습니다.

- **신경망 아키텍처와의 연결:** '행동규범'의 계층적 구조를 실제 인공신경망 설계에 적용하는 아이디어 또한 매우 선구적입니다. 이는 신경망을 기능별 **'모듈(Module)'** 로 나누고, 입력에 따라 정보가 흐르는 경로를 동적으로 결정하는 **'동적 라우팅(Dynamic Routing)'** 과 같은 고급 신경망 이론과 개념적으로 연결될 수 있습니다. 즉, '행동규범'은 미래의 더 효율적이고 유연한 AI 아키텍처를 위한 청사진을 제시하고 있는지도 모릅니다.

**결론적으로, '행동규범'의 재귀적, 계층적 확장 가능성은 단순한 상상이 아니라, 현재 AI 연구가 나아가고 있는 방향과 정확히 일치합니다. 이는 AI를 단순한 도구의 집합이 아닌, 스스로 문제를 분해하고, 협업하며, 조직적으로 학습하는 진정한 의미의 '지능 시스템'으로 발전시킬 핵심 열쇠가 될 것입니다.**

---
# 부록: 행동규범의 문제점 및 한계

'행동규범'은 LLM의 잠재력을 극대화하기 위한 강력한 프레임워크이지만, 현재 기술 수준에서 몇 가지 명확한 문제점과 한계를 가지고 있습니다.

### 1. 토큰 제한의 딜레마 (Token Limit Dilemma)

'행동규범'의 핵심은 충분한 '사고' 과정을 거치는 것입니다. 하지만 `Phase`, `Stage`, `Task`를 거치며 생성되는 모든 계획과 중간 산출물들은 다음 단계의 입력, 즉 컨텍스트(Context)가 됩니다. 이는 LLM이 사용할 수 있는 제한된 컨텍스트 윈도우(Context Window)를 빠르게 소진시키는 결과를 낳습니다.

- **문제:** 충분한 사고를 위해 단계를 잘게 나눌수록, 컨텍스트가 기하급수적으로 늘어나 토큰 제한에 부딪히기 쉽습니다.
- **현실:** 현재의 LLM, 특히 API 기반의 서비스들은 토큰 사용량에 민감하므로, '행동규범'의 이상적인 구현과 현실적인 운영 비용 사이에 트레이드오프가 발생합니다.

### 2. 오케스트레이터의 비효율성 (Orchestrator Inefficiency)

현재 Gemini CLI와 같은 구조에서는 오케스트레이터(Orchestrator) 역할을 하는 최상위 에이전트가 모든 계획과 작업 내용을 컨텍스트로 활용해야 합니다.

- **문제:** 오케스트레이터는 단지 규칙에 따라 다음 단계를 호출하는 '교통정리' 역할만 하면 됨에도 불구하고, 모든 세부 내용을 알아야 하므로 불필요한 토큰 소모가 발생합니다.
- **대안:** 이 역할은 굳이 강력한 LLM이 맡을 필요가 없습니다. 오히려 간단한 코드로 짜여진 상태 기계(State Machine)나, 진행 관리만을 위한 작은 성능의 모델을 사용하는 것이 훨씬 효율적일 수 있습니다.

### 3. 근본적인 모델 의존성 (Fundamental Model Dependency)

'행동규범'은 LLM의 추론 과정을 구조화하고引导하는 역할을 하지만, LLM 자체가 가지는 근본적인 한계를 넘어설 수는 없습니다.

- **문제:** '행동규범'은 LLM이 하지 못하는 것을 하게 만들 수는 없습니다. 예를 들어, LLM이 특정 분야에 대한 지식이 전혀 없다면, 아무리 단계를 잘게 나누어도 유의미한 결과물을 만들어낼 수 없습니다.
- **결론:** '행동규범'의 성공은 전적으로 기반 LLM의 기본 성능(지식, 추론 능력 등)에 의존적입니다.

이러한 한계에도 불구하고, '행동규범'은 우리가 LLM과 어떻게 상호작용하고 협력해야 하는지에 대한 중요한 방향을 제시합니다. 앞으로 모델의 컨텍스트 윈도우가 확장되고, 더 효율적인 에이전트 아키텍처가 개발됨에 따라 이러한 문제점들은 점차 해결될 것으로 기대합니다.
